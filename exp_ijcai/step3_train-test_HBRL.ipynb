{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment #1-2: Derive HBRL rule set\n",
    "\n",
    "Run the following steps.\n",
    "\n",
    "1. Fit the model, i.e. iterate the L1 rule derivation.\n",
    "\n",
    "2. Predict probabilities by running the rule lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "Tensor variable names follow the rules below.\n",
    "\n",
    "* Those small letters to the right denote the rule vectors: s,u,r,...\n",
    "\n",
    "* Capital letters denote tensors: X,...\n",
    "\n",
    "* Small letters followed by an underbar \"\\_\" denotes the rule vectors in the original primitive condition space: s_, u_, r_\n",
    "\n",
    "* Small letters without \"\\_\" at the tail denotes rule vectors in the reduced space: s,u,r\n",
    "\n",
    "* Small letters preceded by \"L1_\" denotes layer-1 rule vectors: L1_s, L1_u, L1_r\n",
    "\n",
    "* \"s\" denotes rule vectors whose elements take the value in [-inf,inf]\n",
    "\n",
    "* \"u\" denotes rule vectors that are converted from \"s\", whose elements take the value in [0,1]\n",
    "\n",
    "* \"r\" denotes the binarized rule vectors that are converted from \"u\", whose elements take the value in {0,1}, i.e. either 0 or 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os,sys,pathlib\n",
    "ROOT_PATH = pathlib.Path.cwd().parent.resolve().as_posix()\n",
    "sys.path.insert(0,ROOT_PATH)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from hbrl_hmc import reset_gpu\n",
    "from ijcai import HBRL\n",
    "from utils import pickle_store, pickle_load\n",
    "from utils import isnotebook\n",
    "\n",
    "import getopt\n",
    "import timeit\n",
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR    = '/media/data/ijcai_2021/'\n",
    "CONFIG_PATH = ROOT_PATH + '/config/ijcai_2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exp_HBRL_sampling(config_file='test_HBRL.toml',debug=100,verbose=False):\n",
    "\n",
    "    # reset GPU\n",
    "    reset_gpu()\n",
    "\n",
    "    # initialize the dict\n",
    "    results = {'classifier':[],'y_prob':[],'y_test':[],'time(sec)':[]}\n",
    "    \n",
    "    # load hyper parameters from config file\n",
    "    config_file_path = CONFIG_PATH + config_file\n",
    "    config = toml.load(config_file_path)\n",
    "    dic    = config['HyperParameters']\n",
    "    dpath  = config['DataPath']\n",
    "    \n",
    "    # load data for k-fold cross valildation\n",
    "    file_name   = dpath['data_file_name']\n",
    "    prefix      = dpath['data_prefix']\n",
    "    if file_name:\n",
    "        data        = pickle_load(directory=DATA_DIR,file_name=file_name)\n",
    "        results['data_file_name'] = file_name\n",
    "    else:\n",
    "        data        = pickle_load(directory=DATA_DIR,prefix=prefix)\n",
    "        results['data_prefix'] = prefix\n",
    "    n_splits    = len(data['train']['X'])\n",
    "\n",
    "    # hyper parameters for L1 Likelihood distribution\n",
    "    dic['_eta_']      = np.asarray(dic['_eta_'])\n",
    "    dic['_rho_']      = 2.0 * np.sum(dic['_eta_'])\n",
    "\n",
    "\n",
    "    # learn the models and derive the label probabilities for the test data\n",
    "#    for i in range(n_splits):\n",
    "    for i in range(1):\n",
    "        print(\"running {}-th round of training and validation round.\".format(i))\n",
    "        # load data\n",
    "        X_train = data['train']['X'][i]\n",
    "        y_train = data['train']['y'][i]\n",
    "        X_test  = data['test']['X'][i]\n",
    "        y_test  = data['test']['y'][i]\n",
    "\n",
    "        # set the dimension parameters\n",
    "        (K_train,N_train)   = X_train.shape\n",
    "        (N_train_y,L_train) = y_train.shape\n",
    "        (K_test,N_test)     = X_test.shape\n",
    "        (N_test_y,L_test)   = y_test.shape\n",
    "        dic['K'] = K = K_train\n",
    "        dic['L'] = L = L_train\n",
    "        assert(K_train==K_test)\n",
    "        assert(L_train==L_test)\n",
    "        assert(N_train==N_train_y)\n",
    "        assert(N_test==N_test_y)\n",
    "\n",
    "        # hyper parameters for L1 Prior distribution\n",
    "        dic['_mu_']        = 0.10 * dic['_zeta_'] / K  # we have to manually adjust the scale factor\n",
    "        dic['L0_pos']      = 0            # first set the L0 layer rule position to 0 \n",
    "        dic['s_prev_']     = None         # No s_prev as L0_pos=0  \n",
    "\n",
    "        if verbose:\n",
    "            for keys in dic.keys():\n",
    "                print(\"dic[\\'{}\\']\\t={}\".format(keys,dic[keys]))\n",
    "    \n",
    "        # set the start time\n",
    "        starttime = timeit.default_timer()\n",
    "\n",
    "        # run model training and test\n",
    "        model  = HBRL(dic,debug=debug,verbose=verbose)\n",
    "        model  = model.fit(X_train,y_train)\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "\n",
    "        #store the results\n",
    "        results['classifier'].append(model)\n",
    "        results['y_prob'].append(y_prob)\n",
    "        results['y_test'].append(y_test)    \n",
    "        results['time(sec)'].append(timeit.default_timer() - starttime)\n",
    "\n",
    "    # set parameters\n",
    "    N_total     = X_train.shape[1] + X_test.shape[1]  # the sizes are the same for all cross-validation folds\n",
    "    K_vecsize   = dic['K_target']    # # of primitive rules to search for at each L1 rules\n",
    "    R_rulesize  = dic['max_rules']   # maximum # of L1 rules to stop the search\n",
    "    U_minrules  = dic['min_rules']   # minmum # of rules left to stop the search\n",
    "    M_minsample = dic['min_samples'] # minimum # of samples to continue searching for another L1 rule\n",
    "    A_Alternate = dic['alternate_eta']  # if true, then use alternate _eta_ to capture both positives and negatives\n",
    "    S_nSamples  = dic['nSamples']    # # of samples at MCMC\n",
    "    T_nTune     = dic['nTune']       # # of tune steps at MCMC\n",
    " \n",
    "    # store the trace file\n",
    "    if pickle_store(results,directory=DATA_DIR,module_name='ijcai_2021',prefix='HBRL_N={}_K={}_R={}_U={}_M={}_A={}_S={}_T={}'.format(N_total,K_vecsize,R_rulesize,U_minrules,M_minsample,A_Alternate,S_nSamples,T_nTune)):\n",
    "        print('experiment results stored successfully')\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_usage(script_name=None):\n",
    "\n",
    "    \"\"\" \n",
    "    Print the usage of this module\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print('usage: {}.py \\n\\\n",
    "    --config_file <config_file name>\\n\\\n",
    "    --debug <debug level>\\n\\\n",
    "    --verbose <True/False>'.format(script_name))\n",
    "\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args=('','')):\n",
    "    '''\n",
    "    Execute the procedures below\n",
    "    '''\n",
    "    # get this script file name\n",
    "    script_name = args[0]\n",
    "    if \"Jupyter\" in script_name:\n",
    "        print('this is from a jupyter nootbook')\n",
    "        Exp_HBRL_sampling(config_file='test_HBRL.toml',debug=100,verbose=False)\n",
    "        return\n",
    "\n",
    "    args = args[1:]\n",
    "    \n",
    "    # read the parameters\n",
    "    params = {'config_file':\"test.toml\",'debug':0,'verbose':False}\n",
    "    try:\n",
    "        opts, _args = getopt.getopt(args,\"h\",['config_file=','debug=','verbose='])\n",
    "    except getopt.GetoptError:\n",
    "        print('args={}'.format(args))\n",
    "        print_usage(script_name=script_name)\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt == '-h':\n",
    "            print_usage(script_name=script_name)\n",
    "            sys.exit()\n",
    "        elif opt in (\"--config_file\"): params['config_file'] = arg\n",
    "        elif opt in (\"--debug\"):       params['debug']       = int(arg)\n",
    "        elif opt in (\"--verbose\"):     params['verbose']     = True if \"True\" in arg else False\n",
    "        else:\n",
    "            pass\n",
    "    print(\"{}(config_file={},debug={},verbose={}\".format(script_name,params['config_file'],params['debug'],params['verbose']))\n",
    "    \n",
    "    # execute the sampling\n",
    "    Exp_HBRL_sampling(config_file=params['config_file'],debug=params['debug'],verbose=params['verbose'])\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if isnotebook():\n",
    "        main(args=((\"Jupyter notebook\",\"\")))\n",
    "    else:\n",
    "        main(sys.argv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
